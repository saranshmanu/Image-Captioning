{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Captioning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "oeR-KTg9NcGe"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhX7_I03p51b",
        "colab_type": "text"
      },
      "source": [
        "# Image Captioning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3l9jrwjqANY",
        "colab_type": "text"
      },
      "source": [
        "The project involves use of both NLP and Computer Vision to create a model that can generate description based on the image feeded as the input in the ML model. I have used Flickr30k model to train the deep learning model. The model describes the image in the best possible way"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgXoR8glOfkq",
        "colab_type": "text"
      },
      "source": [
        "### Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot62cqjmDKPI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0b2406a-2f1d-47eb-ae27-7e9ac8ebf8d2"
      },
      "source": [
        "import keras\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_df-UVIOsK3",
        "colab_type": "text"
      },
      "source": [
        "### Getting the files from the drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QFdwmfyXFOX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ec29056-f7c8-4a73-8974-8229349dce2f"
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fdg-EhNgZZkz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27d4c78e-7934-4169-f530-6cc4ea484618"
      },
      "source": [
        "base_dataset_url = 'drive/My Drive/flikr30k/'\n",
        "os.listdir(base_dataset_url)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['results.csv', 'flickr30k_images', 'x_text.npy', 'y_text.npy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4eunhUWOwh_",
        "colab_type": "text"
      },
      "source": [
        "### Extracting the comments and the image names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeccdr0iaNhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(base_dataset_url + \"results.csv\", sep='|', header=None)\n",
        "df = df[df[2].notnull()]\n",
        "df = df[df[0] != 'image_name']\n",
        "total = 5000\n",
        "comments = df[2].tolist()[:total]\n",
        "image_names = df[0].tolist()[:total]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oCTuUhMI4hi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(comments)):\n",
        "    comments[i] = '<start> ' + comments[i] + ' <end>'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpN_Ta5kLxVL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9209e755-bfd4-4855-b6a7-c6a68281b16c"
      },
      "source": [
        "max_length = 0\n",
        "for i in comments:\n",
        "    if max_length < len(i):\n",
        "        max_length = len(i)\n",
        "print(\"Max sentence length:\", max_length)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length: 287\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeR-KTg9NcGe",
        "colab_type": "text"
      },
      "source": [
        "### Finding the unique words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9L-SR-pbALO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = []\n",
        "for sentence in comments:\n",
        "    words_flag = sentence.split(' ')\n",
        "    words += words_flag\n",
        "words = [i.lower() for i in words if i.isalpha()]\n",
        "unique_words = []\n",
        "for i in words:\n",
        "    if i not in unique_words:\n",
        "        unique_words.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVxHTMKuXSej",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnTWMVo3Kxyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications import VGG16\n",
        "from keras import models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg3oyUtHYCPd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 975
        },
        "outputId": "aa3ae457-2f28-4a6b-ca83-7409a865c559"
      },
      "source": [
        "model = VGG16(include_top = True)\n",
        "model.layers.pop()\n",
        "model = models.Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "=================================================================\n",
            "Total params: 134,260,544\n",
            "Trainable params: 134,260,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHzdNvwE-ygn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_and_load_image(name):\n",
        "    image = load_img(base_dataset_url + 'flickr30k_images/' + name, target_size = (224, 224, 3))\n",
        "    image = img_to_array(image)\n",
        "    image = preprocess_input(image)\n",
        "    image = np.array(image).reshape(1, 224, 224, 3)\n",
        "    y_pred = model.predict(image)\n",
        "    y_pred = y_pred.flatten()\n",
        "    return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_Zs88Wb_1tT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "548d82a4-38d3-4b3b-8bd0-505a35ad797f"
      },
      "source": [
        "images = dict()\n",
        "iteration = 1\n",
        "for i in image_names:\n",
        "    if iteration%1000 == 0:\n",
        "        print('Iteration: {}'.format(iteration))\n",
        "    output = preprocess_and_load_image(i)\n",
        "    images[i] = output\n",
        "    iteration += 1"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 1000\n",
            "Iteration: 2000\n",
            "Iteration: 3000\n",
            "Iteration: 4000\n",
            "Iteration: 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTInzOz7AnRp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shape_image = images['1000268201.jpg'].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFDZQZttOb8R",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-RS00vRSKW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "number_of_words, max_length = 20000, 50\n",
        "tokenizer = Tokenizer(number_of_words)\n",
        "tokenizer.fit_on_texts(comments)\n",
        "words_dictionary = tokenizer.word_index\n",
        "vocab_size = len(words_dictionary) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxg0adODTtId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_text, x_image, y_text = [], [], []\n",
        "comment_sequences = tokenizer.texts_to_sequences(comments)\n",
        "\n",
        "for comment, image_name in zip(comment_sequences, image_names):\n",
        "    for i in range(1, len(comment)):\n",
        "        in_text, out_text = comment[:i], comment[i]\n",
        "        in_text = pad_sequences([in_text], maxlen = max_length).flatten()\n",
        "        out_text = to_categorical(out_text, num_classes = vocab_size)\n",
        "        \n",
        "        x_image.append(images[image_name])\n",
        "        x_text.append(in_text)\n",
        "        y_text.append(out_text)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rJjABSUXJ7yP",
        "colab": {}
      },
      "source": [
        "x_image = np.array(x_image)\n",
        "x_text = np.array(x_text)\n",
        "y_text = np.array(y_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGDt5IytMU1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(base_dataset_url + 'x_text.npy', x_text)\n",
        "np.save(base_dataset_url + 'y_text.npy', y_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMEU2wj0JPIZ",
        "colab_type": "text"
      },
      "source": [
        "### Creating model for Image Captioning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8GqP9sJIrFq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "2300e0d8-a8de-468b-a6f2-fc2890287bb0"
      },
      "source": [
        "from keras import layers, models\n",
        "\n",
        "input_image = layers.Input(shape = (x_image.shape[1],))\n",
        "encoded_image = layers.Dense(256, activation = 'relu')(input_image)\n",
        "input_text = layers.Input(shape = (50,))\n",
        "encoded_text = layers.Embedding(vocab_size, 64, mask_zero = True)(input_text)\n",
        "encoded_text = layers.LSTM(256)(encoded_text)\n",
        "decoder = layers.add([encoded_text, encoded_image])\n",
        "decoder = layers.Dense(256, activation = 'relu')(decoder)\n",
        "output = layers.Dense(vocab_size, activation = 'softmax')(decoder)\n",
        "model = models.Model(inputs = [input_text, input_image], outputs = output)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "print(model.summary())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            (None, 50)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 50, 64)       255104      input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            (None, 4096)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   (None, 256)          328704      embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 256)          1048832     input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 256)          0           lstm_4[0][0]                     \n",
            "                                                                 dense_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 256)          65792       add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 3986)         1024402     dense_11[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 2,722,834\n",
            "Trainable params: 2,722,834\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvUFlxh2EKx5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "459dca60-84b5-48ae-d96e-123a82172fde"
      },
      "source": [
        "hist = model.fit([x_text, x_image], y_text, \n",
        "                  epochs=5, verbose=2, \n",
        "                  batch_size=64,\n",
        "                  validation_data=([x_text, x_image], y_text))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 66455 samples, validate on 66455 samples\n",
            "Epoch 1/5\n",
            " - 146s - loss: 4.9793 - val_loss: 4.2278\n",
            "Epoch 2/5\n",
            " - 144s - loss: 4.0543 - val_loss: 3.6938\n",
            "Epoch 3/5\n",
            " - 142s - loss: 3.6265 - val_loss: 3.3296\n",
            "Epoch 4/5\n",
            " - 145s - loss: 3.3242 - val_loss: 3.0373\n",
            "Epoch 5/5\n",
            " - 143s - loss: 3.0762 - val_loss: 2.7872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUopc7q0pyCY",
        "colab_type": "text"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7nKg7S9ob1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}